# 今回作成するWebアプリ **SIRISA** の概要
- 勉強の解法や疑問点を人間やAIが回答するアプリ
- Gemini APIを利用したAI回答
- 回答はテキストベースだけではなく、HTMLやmarkdown形式を使用した形式もサポート

| 従来のアプリ vs SIRISA | 特徴 |
|:-----------|:------------|
| 従来の質問回答アプリ       | 欲しい情報を短い文章で提供 |
| SIRISA       | 解法の過程をHTMLやmarkdown形式でじっくりと説明 |

:::message
SIRISAは、inputの学習において重要な学習過程を重要視したWebアプリ
:::

# 今日の流れ
1. 追加機能の設計
2. 追加機能の実装
3. 追加機能のテスト
4. 前回のテストのまとめ
5. デバッグ

# 1.追加機能の設計
## 追加機能
- AIのHTMLの回答をXSS対策を施したうえでアニメーションや装飾を充実させる。
    - サブドメイン隔離
    - クッションページ

## XSS対策について
HTMLをユーザやAIが自由に登校することが可能である場合、悪意のあるスクリプトが埋め込まれる可能性がある。  
この攻撃のことをクロスサイトスクリプティング（XSS）攻撃と呼ぶ。 
その為、今回のアプリでは、ユーザはHTMLを投稿できないようにし、AIが生成するHTMLに対してはXSS対策を施したうえでHTMLを表示できるようにする。  
 
以下のようなXSS対策を施すことで、AIが生成するHTMLを安全に表示できると考えた。

- サブドメイン隔離
    - AIやユーザが生成したHTMLを表示する部分を、メインドメインとは異なるサブドメインでホスティングする。
    - これにより、悪意のあるスクリプトがメインドメインに影響を与えることを防ぐ。
    - サブドメインには、セッションCookieやAPIエンドポイントを一切置かない設計を施す。
- クッションページ
    - AIが生成したHTMLを表示する前に、クッションページを挟む。
    - クッションページでは、ユーザに対して警告メッセージを表示し、HTMLの内容を確認させる。
    - これにより、ユーザが悪意のあるスクリプトを実行するリスクを軽減できる。
    - 今回は、Google Safe Browsing APIを使用する。
- 事前学習モデルによるXSS検出
    - HTMLを表示する前に、生成した事前学習モデルを使用してXSS攻撃の可能性を検出する。
    - これにより、悪意のあるスクリプトを含むHTMLを事前にブロックする。

# 2.追加機能の実装




# 3.追加機能のテスト

# 4.前回のテストのまとめ

- 日本語PDF

# 5.デバッグ